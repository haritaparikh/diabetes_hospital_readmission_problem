{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"../\"data/processed_data/x_train.csv\")\n",
    "x_val = pd.read_csv(\"../data/processed_data/x_val.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed_data/y_train.csv\")\n",
    "y_val = pd.read_csv(\"../data/processed_data/y_val.csv\")\n",
    "x_test = pd.read_csv(\"../data/processed_data/x_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed_data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.load(\"../data/processed_data/x_train.npy\")\n",
    "# x_val = np.load(\"../data/processed_data/x_val.npy\")\n",
    "# y_train = np.load(\"../data/processed_data/y_train.npy\")\n",
    "# y_val = np.load(\"../data/processed_data/y_val.npy\")\n",
    "# x_test = np.load(\"../data/processed_data/x_test.npy\")\n",
    "# y_test = np.load(\"../data/processed_data/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15199, 102)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the train dataset by upsampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50663, 102)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 35.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [2, 5, None],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500, 1000],\n",
    "          'min_samples_split':[2, 5, None],\n",
    "          'min_samples_leaf':[1,10,100]}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "rf_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "\n",
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.9957184108334165\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[7027  172]\n",
      " [   0 8000]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      7199\n",
      "           1       0.98      1.00      0.99      8000\n",
      "\n",
      "    accuracy                           0.99     15199\n",
      "   macro avg       0.99      0.99      0.99     15199\n",
      "weighted avg       0.99      0.99      0.99     15199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = rf_model.predict_proba(x_train)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = rf_model.predict_proba(x_val)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                    beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.9960494974728402\n",
      "roc_auc_score: 0.9889825016202203\n",
      "confusion_matrix: \n",
      " [[3018   68]\n",
      " [   0 3429]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3086\n",
      "           1       0.98      1.00      0.99      3429\n",
      "\n",
      "    accuracy                           0.99      6515\n",
      "   macro avg       0.99      0.99      0.99      6515\n",
      "weighted avg       0.99      0.99      0.99      6515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=(rf_model.predict_proba(x_test)[:,1]>cutoff_optimum).astype(int)\n",
    "fbeta=fbeta_score(y_test, \n",
    "                 predictions,\n",
    "                    beta=2)\n",
    "cm = confusion_matrix(y_test, \n",
    "                 predictions)\n",
    "class_report = classification_report(y_test, \n",
    "                 predictions)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_test, predictions)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8172\n",
       "0    7027\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(val_classes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 69.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 110.5min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 120.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.001],\n",
       "                         'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [5, 10],\n",
       "                         'n_estimators': [100, 500], 'tol': [0.001, 0.0001]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500],\n",
    "        'learning_rate':[0.01, 0.001],\n",
    "        'min_samples_leaf':[1,10,100],\n",
    "        'min_samples_split': [5, 10],\n",
    "         'tol': [0.001, 0.0001]}\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "gb_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "gb_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 1.0\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[7199    0]\n",
      " [   0 8000]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7199\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     15199\n",
      "   macro avg       1.00      1.00      1.00     15199\n",
      "weighted avg       1.00      1.00      1.00     15199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = gb_model.predict_proba(x_train)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = gb_model.predict_proba(x_val)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8000\n",
       "0    7199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(val_classes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([ 0.01      ,  0.11090909,  0.21181818,  0.31272727,  0.41363636,\n",
       "        0.51454545,  0.61545455,  0.71636364,  0.81727273,  0.91818182,\n",
       "        1.01909091,  1.12      ,  1.22090909,  1.32181818,  1.42272727,\n",
       "        1.52363636,  1.62454545,  1.72545455,  1.82636364,  1.92727273,\n",
       "        2.02818182,  2.12909091,  2.23      ,  2.33090909,  2.43181818,\n",
       "        2.53272727...\n",
       "        7.07363636,  7.17454545,  7.27545455,  7.37636364,  7.47727273,\n",
       "        7.57818182,  7.67909091,  7.78      ,  7.88090909,  7.98181818,\n",
       "        8.08272727,  8.18363636,  8.28454545,  8.38545455,  8.48636364,\n",
       "        8.58727273,  8.68818182,  8.78909091,  8.89      ,  8.99090909,\n",
       "        9.09181818,  9.19272727,  9.29363636,  9.39454545,  9.49545455,\n",
       "        9.59636364,  9.69727273,  9.79818182,  9.89909091, 10.        ]),\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# model development\n",
    "\n",
    "params = {'penalty':['l1','l2'],\n",
    "          'class_weight':['balanced', None],\n",
    "          'C':np.linspace(0.01,10,100)}\n",
    "model = LogisticRegression()\n",
    "\n",
    "lr_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "\n",
    "lr_model.fit(x_train_scaled, \n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.9999750006249843\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[7198    1]\n",
      " [   0 8000]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7199\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     15199\n",
      "   macro avg       1.00      1.00      1.00     15199\n",
      "weighted avg       1.00      1.00      1.00     15199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = lr_model.predict_proba(x_train_scaled)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = lr_model.predict_proba(x_val_scaled)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 0.8474618160249122\n",
      "roc_auc_score: 0.5\n",
      "confusion_matrix: \n",
      " [[   0 3086]\n",
      " [   0 3429]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3086\n",
      "           1       0.53      1.00      0.69      3429\n",
      "\n",
      "    accuracy                           0.53      6515\n",
      "   macro avg       0.26      0.50      0.34      6515\n",
      "weighted avg       0.28      0.53      0.36      6515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions=(lr_model.predict_proba(x_test)[:,1]>cutoff_optimum).astype(int)\n",
    "fbeta=fbeta_score(y_test, \n",
    "                 predictions,\n",
    "                    beta=2)\n",
    "cm = confusion_matrix(y_test, \n",
    "                 predictions)\n",
    "class_report = classification_report(y_test, \n",
    "                 predictions)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_test, predictions)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDClassifier(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 1e-05],\n",
       "                         'max_iter': [500, 1000, 1500], 'penalty': ['l1', 'l2'],\n",
       "                         'tol': [0.001, 0.0001]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# model development\n",
    "\n",
    "params = {'penalty':['l1','l2'],\n",
    "          'tol':[0.001, 0.0001],\n",
    "          'alpha': [0.0001, 0.00001],\n",
    "         'max_iter': [500, 1000, 1500]}\n",
    "\n",
    "model = SGDClassifier(loss='hinge')\n",
    "\n",
    "svm_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='f1')\n",
    "svm_model.fit(x_train_scaled, \n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Train***********\n",
      "fbeta: 1.0\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[23998     0]\n",
      " [    0 26665]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23998\n",
      "           1       1.00      1.00      1.00     26665\n",
      "\n",
      "    accuracy                           1.00     50663\n",
      "   macro avg       1.00      1.00      1.00     50663\n",
      "weighted avg       1.00      1.00      1.00     50663\n",
      "\n",
      "**********Validation***********\n",
      "fbeta: 1.0\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[7199    0]\n",
      " [   0 8000]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7199\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     15199\n",
      "   macro avg       1.00      1.00      1.00     15199\n",
      "weighted avg       1.00      1.00      1.00     15199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on validation dataset\n",
    "train_classes = svm_model.predict(x_train_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_train, \n",
    "                 train_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_train, \n",
    "                     train_classes)\n",
    "class_report = classification_report(y_train, \n",
    "                                    train_classes)\n",
    "\n",
    "print(\"**********Train***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_train, train_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n",
    "\n",
    "# prediction on validation dataset\n",
    "\n",
    "val_classes = svm_model.predict(x_val_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"**********Validation***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, val_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 16.3min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={'max_iter': [500, 1000, 1500], 'tol': [0.0001, 1e-05]},\n",
       "             scoring='f1', verbose=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# model development\n",
    "\n",
    "params = {'tol':[0.0001, 0.00001],\n",
    "         'max_iter': [500, 1000, 1500]}\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "svc_svm_model = GridSearchCV(model,\n",
    "                            cv=10,\n",
    "                            param_grid=params,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5,\n",
    "                            scoring='f1')\n",
    "svc_svm_model.fit(x_train_scaled, \n",
    "                  y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Train***********\n",
      "fbeta: 1.0\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[23998     0]\n",
      " [    0 26665]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23998\n",
      "           1       1.00      1.00      1.00     26665\n",
      "\n",
      "    accuracy                           1.00     50663\n",
      "   macro avg       1.00      1.00      1.00     50663\n",
      "weighted avg       1.00      1.00      1.00     50663\n",
      "\n",
      "**********Validation***********\n",
      "fbeta: 1.0\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[7199    0]\n",
      " [   0 8000]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7199\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     15199\n",
      "   macro avg       1.00      1.00      1.00     15199\n",
      "weighted avg       1.00      1.00      1.00     15199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on validation dataset\n",
    "train_classes = svc_svm_model.predict(x_train_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_train, \n",
    "                 train_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_train, \n",
    "                     train_classes)\n",
    "class_report = classification_report(y_train, \n",
    "                                    train_classes)\n",
    "\n",
    "print(\"**********Train***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_train, train_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n",
    "\n",
    "# prediction on validation dataset\n",
    "\n",
    "val_classes = svc_svm_model.predict(x_val_scaled)\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"**********Validation***********\")\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, val_classes)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 110.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 120.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 41.4min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 83.9min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 91.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 84.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 91.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 83.8min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 91.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 84.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 91.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 59.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 104.6min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 116.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 49.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 51.1min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 52.8min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 36.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 38.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1728 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2520 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3456 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('gb',\n",
       "                                GridSearchCV(cv=10,\n",
       "                                             estimator=GradientBoostingClassifier(),\n",
       "                                             n_jobs=-1,\n",
       "                                             param_grid={'learning_rate': [0.01,\n",
       "                                                                           0.001],\n",
       "                                                         'min_samples_leaf': [1,\n",
       "                                                                              10,\n",
       "                                                                              100],\n",
       "                                                         'min_samples_split': [5,\n",
       "                                                                               10],\n",
       "                                                         'n_estimators': [100,\n",
       "                                                                          500],\n",
       "                                                         'tol': [0.001,\n",
       "                                                                 0.0001]},\n",
       "                                             scoring='f1', verbose=5)),\n",
       "                               ('lr',\n",
       "                                GridSearchCV(cv=10,\n",
       "                                             estimator=LogisticRegression(),\n",
       "                                             n_jobs=-1,\n",
       "                                             param_gri...\n",
       "        7.07363636,  7.17454545,  7.27545455,  7.37636364,  7.47727273,\n",
       "        7.57818182,  7.67909091,  7.78      ,  7.88090909,  7.98181818,\n",
       "        8.08272727,  8.18363636,  8.28454545,  8.38545455,  8.48636364,\n",
       "        8.58727273,  8.68818182,  8.78909091,  8.89      ,  8.99090909,\n",
       "        9.09181818,  9.19272727,  9.29363636,  9.39454545,  9.49545455,\n",
       "        9.59636364,  9.69727273,  9.79818182,  9.89909091, 10.        ]),\n",
       "                                                            'class_weight': ['balanced',\n",
       "                                                                             None],\n",
       "                                                            'penalty': ['l1',\n",
       "                                                                        'l2']},\n",
       "                                                scoring='f1', verbose=5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [('gb', gb_model),\n",
    "             ('lr', lr_model)]\n",
    "final_estimator = lr_model\n",
    "              \n",
    "stacking_model = StackingClassifier(estimators = estimators, \n",
    "                                  final_estimator = final_estimator)\n",
    "stacking_model.fit(x_train,\n",
    "                   y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta: 1.0\n",
      "roc_auc_score: 1.0\n",
      "confusion_matrix: \n",
      " [[7199    0]\n",
      " [   0 8000]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7199\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     15199\n",
      "   macro avg       1.00      1.00      1.00     15199\n",
      "weighted avg       1.00      1.00      1.00     15199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting the cut-off for determining hardclasses\n",
    "\n",
    "# prediction on training dataset\n",
    "predicted_train = stacking_model.predict_proba(x_train_scaled)[:,1]\n",
    "actual = y_train.values.ravel()\n",
    "\n",
    "# fbetas statistic \n",
    "\n",
    "cutoffs = np.linspace(0.001,0.999,999)\n",
    "fbetas=[]\n",
    "for cutoff in cutoffs:    \n",
    "    predicted=(predicted_train>cutoff).astype(int)  \n",
    "    fbetas.append(fbeta_score(actual, predicted, beta=2))\n",
    "    \n",
    "# list(zip(cutoffs,KS_all))\n",
    "\n",
    "cutoff_optimum = cutoffs[fbetas == max(fbetas)][0]\n",
    "predicted_val = stacking_model.predict_proba(x_val_scaled)[:,1]\n",
    "\n",
    "val_classes = (predicted_val>cutoff_optimum).astype(int)\n",
    "# pd.Series(val_classes).value_counts()\n",
    "\n",
    "fbeta=fbeta_score(y_val, \n",
    "                 val_classes,\n",
    "                  beta=2)\n",
    "cm = confusion_matrix(y_val, \n",
    "                     val_classes)\n",
    "class_report = classification_report(y_val, \n",
    "                                    val_classes)\n",
    "\n",
    "print(\"fbeta:\", fbeta)\n",
    "print(\"roc_auc_score:\",roc_auc_score(y_val, predicted_val)) # AUROC represents the likelihood of the model distinguishing observations from two classes.\n",
    "print(\"confusion_matrix: \\n\",cm)\n",
    "print(\"classification_report: \\n\",class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(y_val).value_counts()\n",
    "# pd.Series(val_classes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final predictions using stacking model based on fbeta score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=(stacking_model.predict_proba(x_test)[:,1]>cutoff_optimum).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submissions=pd.DataFrame({'V86':predictions})\n",
    "# submissions.to_csv('output/prediction_submission_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle_model(model_parameters, model_path, file_opts):\n",
    "    # Save the model to disk\n",
    "    with open(model_path, file_opts) as pickle_out:\n",
    "        pickle.dump(model_parameters, pickle_out)\n",
    "\n",
    "def load_pickle_model(model_path, file_opts):\n",
    "    # Load the model from disk\n",
    "    with open(model_path, file_opts) as pickle_in:\n",
    "        return pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-72c2bf548745>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# save models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m save_pickle_model(rf_model.best_estimator_, os.path.join(\n\u001b[0m\u001b[0;32m     11\u001b[0m     model_path, \"rf_model.pickle\"), \"wb\") \n\u001b[0;32m     12\u001b[0m save_pickle_model(gb_model.best_estimator_, os.path.join(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_path = \"../output\"\n",
    "model_path = os.path.join(output_path, \"model\", \"artifact\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)  \n",
    "    \n",
    "# save models\n",
    "\n",
    "save_pickle_model(rf_model.best_estimator_, os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"wb\") \n",
    "save_pickle_model(gb_model.best_estimator_, os.path.join(\n",
    "    model_path, \"gb_model.pickle\"), \"wb\") \n",
    "save_pickle_model(lr_model.best_estimator_, os.path.join(\n",
    "    model_path, \"lr_model.pickle\"), \"wb\") \n",
    "save_pickle_model(svm_model.best_estimator_, os.path.join(\n",
    "    model_path, \"svm_model.pickle\"), \"wb\") \n",
    "save_pickle_model(svc_svm_model.best_estimator_, os.path.join(\n",
    "    model_path, \"svc_svm_model.pickle\"), \"wb\") \n",
    "save_pickle_model(stacking_model, os.path.join(\n",
    "    model_path, \"stacking_model.pickle\"), \"wb\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "\n",
    "            \n",
    "rf_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"rb\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
